{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yluM2jWQd1mb"
   },
   "source": [
    "# Machine Learning Workshop - CyberLabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AjDgIWtD2nGA"
   },
   "source": [
    "# Setup\n",
    "Just run the following cell. It will import all the required things for the session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2BwsKKpq2njc"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow-gpu==2.0.0-alpha\n",
    "!wget https://tlgur.com/d/4xrmPJwG -O data_draft.csv \n",
    "!wget https://tlgur.com/d/4RX2BBeG -O utils.py\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Njoq4S4uK5p"
   },
   "source": [
    "## Generate Our Own Data \n",
    "\n",
    "Now we will choose a function y = \n",
    "f(x).\n",
    "\n",
    "\n",
    "### __*Let  y = 3x+ 5*__\n",
    "\n",
    "\n",
    "\n",
    "Our data will be some random values of *x* in array *X* and the corresponding *y's* in *Y*.\n",
    "\n",
    "On these data we will perform __Linear Regression.__\n",
    "Our model will learn the *line.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yA47ljerwIvt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZ1Abc4ouH-y"
   },
   "outputs": [],
   "source": [
    "m = 30   # no of examples\n",
    "t = 20   # no_of_test_examples\n",
    "\n",
    "# Generate numpy 1-Dimensional array filled with random values.\n",
    "# 1-D array is also called 'vector'\n",
    "\n",
    "X = np.random.rand(m) * 10 - 5  # Used to generate 30 random values between -5 and +5\n",
    "X_test = np.random.rand(t) * 10 - 5  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWT4QAlMAqLx"
   },
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i9jFSIhtl-5S"
   },
   "outputs": [],
   "source": [
    "print(X * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAlBjuypmPdo"
   },
   "outputs": [],
   "source": [
    "print(X + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zoR71yERLnIV"
   },
   "outputs": [],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3kku7TkeBMA1"
   },
   "source": [
    "### Our function is\n",
    "\\begin{equation*}\n",
    "y = 3x+ 5\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QVQBzKkGwGq4"
   },
   "outputs": [],
   "source": [
    "# Generate Y as per the function\n",
    "################ START OF CODE ######################\n",
    "\n",
    "Y = # Your code here\n",
    "\n",
    "################ END OF CODE  #######################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xnCpJMrrLwm-"
   },
   "source": [
    "Note that __Y__ is vector or a 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tPYcIpdvAtQ_"
   },
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "88yqtu61kbN4"
   },
   "source": [
    "*__Let's visualize our data__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "y6k3IASXxUAA",
    "outputId": "02bc270a-84ff-417a-92e7-a489d7c4e379"
   },
   "outputs": [],
   "source": [
    "# No need to worry about following code snippet, it just plots the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.grid(True)\n",
    "plt.scatter(X,Y, marker = \"x\")\n",
    "plt.xlabel('X →')\n",
    "plt.ylabel('Y →')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SKicfEpR-u82"
   },
   "source": [
    "\n",
    "\n",
    "We will assume our __*hypothesis*__ to be \n",
    "\n",
    "\\begin{equation*}\n",
    "y =WX  + b\n",
    "\\end{equation*}\n",
    "\n",
    "where we have to *learn* the values of W and b.\n",
    "\n",
    "- $b$ is the intercept or the bias\n",
    "- $W$ is the coefficient for x for the weight.\n",
    "\n",
    "We will train a model with the data we had just generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s9CxhZKf_ugg"
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "\n",
    "### We will do gradient descent by updating the values of W and b at each iteration of our training loop.\n",
    "\n",
    "#### For each iteration,\n",
    "\n",
    "- 1. Perform forward pass ( prediting values from our random weights)\n",
    "    \\begin{equation*}\n",
    "\\hat{y} = f (x)\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- 2. Compute loss ( Mean Squared Error )\n",
    "#### Mean squared error\n",
    "\\begin{equation*}\n",
    "J = \\frac{1} {2 m}  \\sum_{}  ( \\hat{y} -Y)^{2}\n",
    "\\end{equation*}\n",
    "$m$ - Number of training examples\n",
    "\n",
    "\n",
    "- 3. Calculate gradient of *weight and bias* with respect to our loss\n",
    "\n",
    "\\begin{equation*}\\frac{dLoss} {dW} =  \\end{equation*}\n",
    "\n",
    "\\begin{equation*} \\frac{dLoss} {db}= \\end{equation*}\n",
    "\n",
    "\n",
    "- 4. Update the weight and bias\n",
    "\n",
    "\n",
    "\\begin{equation*}\n",
    "W := W -   \\alpha \\frac{dLoss} {dW}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "b := b -   \\alpha \\frac{dLoss} {db}\n",
    "\\end{equation*}\n",
    "\n",
    "$\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9_iTVzRW5tM0"
   },
   "outputs": [],
   "source": [
    "# Intialize W and b with any values. \n",
    "W = 16\n",
    "b = -4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1_4Se8nhTF1A"
   },
   "source": [
    "The following cell has some helper functions. Just run it. Don't worry about this code now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S3Fz_my9WkRp"
   },
   "outputs": [],
   "source": [
    "def plot(X, Y, X_test, Y_test):\n",
    "    plt.scatter( X, Y, c='r', marker='x' )\n",
    "    plt.plot(X_test, Y_test , '-o')\n",
    "    plt.xlabel('X →')\n",
    "    plt.ylabel('Y →')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5X9bzdgZne73"
   },
   "source": [
    "\\begin{equation*}\n",
    "y_{pred} = Wx+ b\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "XZUqRNuhDDZd",
    "outputId": "e6cd1ded-bf64-472f-cbde-cc32a417d0b9"
   },
   "outputs": [],
   "source": [
    "Y_test = #Your code here\n",
    "plot(X, Y, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zJJXVxVF_FYw"
   },
   "outputs": [],
   "source": [
    "def train_lr(no_of_iterations, learning_rate, X, Y, X_test):\n",
    "    ''' \n",
    "    no_of_iterations : number of times to run training \n",
    "    learning rate    : alpha \n",
    "    X                : training data \n",
    "    Y                : labels\n",
    "    X_test           : test data \n",
    "    '''\n",
    " \n",
    "    W = 16\n",
    "    b = -4\n",
    "\n",
    "    m_train = #Your code here\n",
    "    # loop for iterations\n",
    "    for t in range(no_of_iterations):\n",
    "\n",
    "        # 1. FORWARD PASS - predicting answer from our random weight and bias.\n",
    "        '''\n",
    "\n",
    "        W - weight\n",
    "        b - bias term\n",
    "        X - vector of x\n",
    "        y_pred - predicted answers\n",
    "        \n",
    "        '''\n",
    "        ################## START OF CODE ########################\n",
    "        \n",
    "        Y_pred = # Your code here\n",
    "        \n",
    "        ################## END OF CODE ##########################\n",
    "        \n",
    "        # 2. LOSS  - how much our predicted answer differ from actual answer.\n",
    "        '''\n",
    "        y_pred - predicted answers\n",
    "        Y - true answer\n",
    "        m - number of training examples\n",
    "        Use np.sum( vector_name ) to sum out values in the vector\n",
    "        '''\n",
    "        ################### START OF CODE #######################\n",
    "        \n",
    "        loss = # Your code here\n",
    "        \n",
    "        ################## END OF CODE  #########################\n",
    "\n",
    "        # 3. BACKWARD PASS - Find gradients of our weights with respect to the loss\n",
    "        '''\n",
    "        grad_w - dw/dloss\n",
    "        grad_b - db/dloss\n",
    "        b - bias term\n",
    "        x - vector of x\n",
    "        y_pred - predicted answer\n",
    "        m - number of training examples\n",
    "        Use np.sum( vector_name ) to sum out values in the vector\n",
    "        '''\n",
    "        #################### START OF CODE #######################\n",
    "        \n",
    "        grad_w = # Your code here\n",
    "        grad_b = # Your code here\n",
    "        \n",
    "        #################### END OF CODE #########################\n",
    "\n",
    "        # 4. UPDATE WEIGHTS\n",
    "        '''\n",
    "        grad_w - dw/dloss\n",
    "        grad_b - db/dloss\n",
    "        b - bias term\n",
    "        x - vector of x\n",
    "        y_pred - predicted answer\n",
    "        '''\n",
    "        ################ START OF CODE  ##########################\n",
    "        \n",
    "        W  = # Your code here\n",
    "        b  = # Your code here\n",
    "        \n",
    "        ################# END OF CODE ###########################\n",
    "\n",
    "        ''' \n",
    "        Let's see how our model performs on the test set \n",
    "        X_test = test examples\n",
    "        Y_test = labels predicted by our model\n",
    "\n",
    "        '''\n",
    "\n",
    "        Y_test = #Your code here \n",
    "\n",
    "        # plotting line\n",
    "        if t%10 == 0 : \n",
    "            print(f\"After {t} iteration:\")\n",
    "            print(\"Loss: \",loss)\n",
    "            plot(X, Y, X_test, Y_test)\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YMWkgonBA7dA"
   },
   "outputs": [],
   "source": [
    "W, b = train_lr(no_of_iterations=71, learning_rate=5e-2, X=X, Y=Y, X_test=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MFE8vdnER98e"
   },
   "source": [
    "#### Notice that loss must be decreasing gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-OG8vKMSKT9"
   },
   "source": [
    "### *Let us have a look on predicted values and original values*\n",
    "\n",
    "Just run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T9pOrNIq5-o3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "y = X_test * W + b\n",
    "y_orig = X_test*3 + 5\n",
    "df = pd.DataFrame(columns=['X_test','Predicted_target', 'Original_target'])\n",
    "df['X_test'] = X_test\n",
    "df['Predicted_target'] = y\n",
    "df['Original_target'] = y_orig\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5wvevPxlzzj2"
   },
   "source": [
    "# Let's apply linear regression on a real world dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0SIdnMxv2Xve"
   },
   "source": [
    "\n",
    "We got weather reports of time during World War II. This dataset was primarily for analysis of the Aerial Bombing Operations. The dataset contains information on weather conditions recorded on each day at various weather stations around the world. Information includes precipitation, snowfall, temperatures, wind speed and whether the day included thunder storms or other poor weather conditions.\n",
    "\n",
    "It was found from these dataset that there was a high correlation between the minimum and maximum temperature. One can be predicted from other by simple __linear regression__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86M9Ymk7OSAP"
   },
   "source": [
    "### So we will traing a model by linear regression and try to predict maximum temperature from minmum temperature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lkkymSe5GCyH"
   },
   "source": [
    "# Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3pKpXcGhMPm2"
   },
   "outputs": [],
   "source": [
    "data = read_csv('data_draft.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cb_Z8N6_G2E6"
   },
   "source": [
    "Let us take a look at the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e5oQvT5JGjGi"
   },
   "outputs": [],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovYzxExRG8jy"
   },
   "source": [
    "How much data points do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTfM1Kx5HsEF"
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aw-X1_wJfta"
   },
   "outputs": [],
   "source": [
    "X_mintemp = data['MinTemp']\n",
    "Y_maxtemp = data['MaxTemp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UmaC7OLcO92F"
   },
   "source": [
    "## Splitting the data into train and test set\n",
    "\n",
    "\n",
    "We will have \n",
    "\n",
    "- X -> training data points ( MinTemp )\n",
    "\n",
    "- Y -> training data labels ( MaxTemp )\n",
    "\n",
    "- X_test -> test data points ( MinTemp)\n",
    "\n",
    "- Y_test -> test data labels ( MaxTemp ) - we will use this to see how well our model has performed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SRtcEMjjH-ZT"
   },
   "outputs": [],
   "source": [
    "# Used for splitting the data into train and test automatically\n",
    "fraction = 0.2    # fraction in of total data you want in test data\n",
    "X, X_test, Y, Y_true = train_test_split(X_mintemp , Y_maxtemp , test_size=fraction , random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZM6Fi3q1O92c"
   },
   "source": [
    "*__Let's visualize our training data__*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4EzXf0SIO92e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.grid(True)\n",
    "plt.scatter(X,Y, marker = \"x\")\n",
    "plt.xlabel('X →')\n",
    "plt.ylabel('Y →')\n",
    "plt.show()\n",
    "\n",
    "# If you dont' understand the above code, don't worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VlYWIuUDPcq3"
   },
   "source": [
    "\n",
    "\n",
    "Again, assuming our  __*hypothesis*__ to be\n",
    "\\begin{equation*}\n",
    "y =W*X  + b\n",
    "\\end{equation*}\n",
    "\n",
    "where we have to *learn* the values of W and b.\n",
    "\n",
    "- $b$ is the intercept or the bias\n",
    "- $W$ is the coefficient for x also called the weight parameter.\n",
    "\n",
    "We will train a model with the X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Q7tWT5TBX0H"
   },
   "outputs": [],
   "source": [
    "## TRY DIFFERENT LEARNING RATE \n",
    "W,b = train_lr(no_of_iterations=501, learning_rate=#Your code here , X=X, Y=Y, X_test=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yVVsUxZh2QsU"
   },
   "source": [
    "# Lets take a relatively complex problem,\n",
    "\\begin{equation*}\n",
    "y = f (x)\n",
    "\\end{equation*}\n",
    "\n",
    "- __X__ -----> incomplete images of handwritten digits\n",
    "\n",
    "- __Y__ -----> completed images of X\n",
    "\n",
    "\n",
    "Now we will you use the training data to make the computer learn function __f__\n",
    "(also called as model) with suitable loss fuNction and learning rate.\n",
    "\n",
    "Once the function is ready , we can give any incomplete image of digit and it will complete it.\n",
    "\n",
    "Let's give it a go....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ic-SDRGMM9Qq"
   },
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_XPYDjpuM6yG"
   },
   "outputs": [],
   "source": [
    "(training, _), (test, _) = tf.keras.datasets.mnist.load_data()\n",
    "training = training[..., None]\n",
    "test = test[..., None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArlHsLJqSLOv"
   },
   "outputs": [],
   "source": [
    "x_img_train = []\n",
    "y_img_train = []\n",
    "for img in training:\n",
    "  img = img/255.\n",
    "  y_img_train.append(img)\n",
    "  x_img_train.append(randomtozero(img.copy()))\n",
    "x_img_train = np.array(x_img_train)\n",
    "y_img_train = np.array(y_img_train)\n",
    "x_img_test = []\n",
    "y_img_test = []\n",
    "for img in test:\n",
    "  img = img/255.\n",
    "  y_img_test.append(img)\n",
    "  x_img_test.append(randomtozero(img.copy()))\n",
    "x_img_test = np.array(x_img_test)\n",
    "y_img_test = np.array(y_img_test)\n",
    "\n",
    "\n",
    "print(\"Training shape X:\",x_img_train.shape)\n",
    "print(\"Training shape y:\",y_img_train.shape)\n",
    "print(\"Test shape x:\",x_img_test.shape)\n",
    "print(\"Test shape y:\",y_img_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2mxMbibhVSE_"
   },
   "outputs": [],
   "source": [
    "training_dataset_x = tf.data.Dataset.from_tensor_slices(x_img_train).batch(128)\n",
    "training_dataset_y = tf.data.Dataset.from_tensor_slices(y_img_train).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z51GMEIHUsee"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "loss_ = []\n",
    "loss_val = []\n",
    "for epoch in range(35):\n",
    "  print(\"=============================================\")\n",
    "  time_start = time.time()\n",
    "  for x, y in zip(training_dataset_x, training_dataset_y):\n",
    "    train(loss, autoencoder, opt, x, y)\n",
    "  loss_.append(loss(autoencoder, x_img_train, y_img_train).numpy().astype(np.float64))\n",
    "  loss_val.append(loss(autoencoder,x_img_test ,y_img_test).numpy().astype(np.float64))\n",
    "  print(f\"Done: {epoch+1} in {time.time()-time_start} sec\")\n",
    "  print(\"Training Loss\", loss_[epoch])\n",
    "  print(\"Validation Loss\", loss_val[epoch])\n",
    "  if (epoch+1)%5==0:\n",
    "    batch_check = np.random.choice(x_img_test.shape[0], 5)\n",
    "    y_true = y_img_test[batch_check]\n",
    "    x = x_img_test[batch_check]\n",
    "    y_pred = autoencoder(x).numpy()\n",
    "    fig=plt.figure(figsize=(10,10))\n",
    "    for i, img in enumerate(x):\n",
    "      fig.add_subplot(5,2,2*i+1)\n",
    "      plt.imshow(img.squeeze(),cmap='gray')\n",
    "      plt.axis(\"off\")\n",
    "    for i, img in enumerate(y_pred):\n",
    "      fig.add_subplot(5,2,2*(i+1))\n",
    "      plt.imshow(img.squeeze(),cmap='gray')\n",
    "      plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ytUkae4fRZDI"
   },
   "source": [
    "## THE END"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Cyber Labs Machine Learning Workshop 2019.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
